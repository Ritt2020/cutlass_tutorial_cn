# CuTe Copy 和 TMA

> CuTe 提供了一套强大的拷贝算法，能够根据 Tensor 的类型自动选择最优的硬件拷贝指令。本章将介绍 CuTe 的 copy 算法，包括普通拷贝和 TMA（Tensor Memory Accelerator）拷贝。学习本章后，你将能够高效地在不同内存层次之间移动数据。
>
> **配套代码示例**：[code/06_cute_copy](../code/06_cute_copy)

## 环境要求
+ CUTLASS 3.x
+ NVCC with C++ 17
+ **TMA 部分**需要 **Hopper (sm_90)** 或更高架构

## 核心概念

### 为什么需要专门的 Copy 算法？

在 GPU 编程中，数据移动往往是性能瓶颈。不同的内存层次（全局内存、共享内存、寄存器）之间的拷贝有不同的最优方法：

- **全局内存 → 共享内存**：可以使用异步拷贝指令（`cp.async`）
- **全局内存 → 寄存器**：可以使用向量化加载（`ld.global.v4`）
- **共享内存 → 寄存器**：可以使用向量化加载，需要避免 bank conflict
- **Hopper 架构**：可以使用 TMA 指令实现高效的块级拷贝

传统的手动拷贝代码难以针对不同场景选择最优指令，而 CuTe 的 `copy` 算法可以**根据 Tensor 的类型自动派发到最优实现**。

### Copy 的设计哲学

CuTe 的 `copy` 算法体现了以下设计理念：

1. **类型驱动派发**：根据源和目标 Tensor 的类型（数据类型、内存空间、布局）自动选择最优实现
2. **统一接口**：所有拷贝操作使用相同的接口 `copy(src, dst)`
3. **可定制性**：通过 `Copy_Atom` 可以显式指定拷贝实现
4. **零开销抽象**：静态信息在编译期解析，运行时无额外开销

---

## 1. 普通 Copy

### 1.1 Copy 接口

根据 [NVIDIA CUTLASS 文档](https://docs.nvidia.com/cutlass/media/docs/cpp/cute/04_algorithms.html)，CuTe 的 `copy` 算法有两个主要重载：

#### 重载 1：自动派发（推荐）

最简单的形式，只需要提供源 Tensor 和目标 Tensor：

```cpp
template <class SrcEngine, class SrcLayout,
          class DstEngine, class DstLayout>
CUTE_HOST_DEVICE
void
copy(Tensor<SrcEngine, SrcLayout> const& src,
     Tensor<DstEngine, DstLayout>      & dst);
```

**特点**：
- CuTe 根据 Tensor 的类型**自动选择**最优的拷贝实现
- 对于大多数场景，这个接口就足够了
- 编译器可以根据静态类型信息进行优化

#### 重载 2：显式指定 Copy_Atom

如果需要覆盖默认实现，可以显式指定 `Copy_Atom`：

```cpp
template <class... CopyArgs,
          class SrcEngine, class SrcLayout,
          class DstEngine, class DstLayout>
CUTE_HOST_DEVICE
void
copy(Copy_Atom<CopyArgs...>       const& copy_atom,
     Tensor<SrcEngine, SrcLayout> const& src,
     Tensor<DstEngine, DstLayout>      & dst);
```

**特点**：
- `Copy_Atom` 让调用者可以覆盖默认实现
- 用于需要精确控制拷贝行为的场景
- 在后续的 MMA（矩阵乘累加）章节中会详细介绍

### 1.2 基本使用示例

#### 示例 1：简单的 Tensor 拷贝

```cpp
#include <cute/tensor.hpp>
using namespace cute;

// 源数据和目标数据
float src_data[128];
float dst_data[128];

// 初始化源数据
for (int i = 0; i < 128; ++i) {
    src_data[i] = i * 1.0f;
}

// 创建 Tensor
auto src = make_tensor(src_data, make_shape(Int<128>{}));
auto dst = make_tensor(dst_data, make_shape(Int<128>{}));

// 拷贝！
copy(src, dst);

// 验证结果
for (int i = 0; i < 128; ++i) {
    assert(dst_data[i] == src_data[i]);
}
```

**说明**：
- 这是最简单的拷贝形式
- CuTe 会自动生成高效的拷贝代码
- 如果 shape 是静态的（`Int<128>`），编译器可以完全展开循环

#### 示例 2：二维 Tensor 拷贝

```cpp
// 8×16 的矩阵（列主序）
float src_matrix[128];
float dst_matrix[128];

auto src = make_tensor(src_matrix, make_shape(Int<8>{}, Int<16>{}));
auto dst = make_tensor(dst_matrix, make_shape(Int<8>{}, Int<16>{}));

// 拷贝整个矩阵
copy(src, dst);
```

**关键点**：
- 源和目标 Tensor 的 **shape 必须兼容**（参考第03章：布局兼容性）
- 源和目标可以有不同的 stride（不同的内存布局）
- CuTe 会按照逻辑列序遍历数据

#### 示例 3：部分拷贝（使用切片）

```cpp
auto src = make_tensor(src_ptr, make_shape(Int<16>{}, Int<16>{}));
auto dst = make_tensor(dst_ptr, make_shape(Int<16>{}, Int<16>{}));

// 只拷贝第 5 列
copy(src(_, 5), dst(_, 5));

// 只拷贝前 8 行
copy(src(make_coord(0, 7), _), dst(make_coord(0, 7), _));

// 拷贝左上角 4×4 的子块
auto src_tile = local_tile(src, make_shape(Int<4>{}, Int<4>{}), make_coord(0, 0));
auto dst_tile = local_tile(dst, make_shape(Int<4>{}, Int<4>{}), make_coord(0, 0));
copy(src_tile, dst_tile);
```

**技巧**：
- 使用 `_` 占位符进行切片
- 使用 `local_tile` 提取子区域
- 确保源和目标切片的 shape 匹配

### 1.3 通用 Copy 实现原理

根据 [CUTLASS 文档](https://docs.nvidia.com/cutlass/media/docs/cpp/cute/04_algorithms.html)，一个通用的 `copy` 实现看起来像这样：

```cpp
template <class TA, class ALayout,
          class TB, class BLayout>
CUTE_HOST_DEVICE
void
copy(Tensor<TA, ALayout> const& src,  // 任意逻辑形状
     Tensor<TB, BLayout>      & dst)  // 任意逻辑形状
{
  for (int i = 0; i < size(dst); ++i) {
    dst(i) = src(i);
  }
}
```

**工作原理**：
1. 用一维索引 `i` 按照**列序（colexicographical order）**遍历两个 Tensor
2. 这种遍历方式与 Tensor 的具体 stride 无关
3. Layout 会自动将一维索引映射到正确的内存位置

#### 这个简单实现如何变得高效？

CuTe 的优化策略包括：

| 优化技术 | 说明 |
|---------|------|
| **指令选择** | 根据内存类型选择最优指令（如 `cp.async`、`ldgsts`） |
| **向量化** | 如果布局允许，自动合并多个访问为向量化指令 |
| **预测验证** | 编译期验证拷贝指令是否适用于源和目标 Tensor |
| **循环展开** | 静态 shape 时，编译器可以完全展开循环 |

**示例：向量化优化**

假设有以下拷贝：
```cpp
// 128 个 float，连续存储
auto src = make_tensor(make_gmem_ptr(src_ptr), make_shape(Int<128>{}));
auto dst = make_tensor(make_smem_ptr(dst_ptr), make_shape(Int<128>{}));
copy(src, dst);
```

CuTe 可能会：
1. 检测到源和目标都是连续存储的
2. 将 4 个 `ld.global.f32` 合并为 1 个 `ld.global.v4.f32`
3. 使用 `cp.async.cg` 异步拷贝指令（如果支持）

**这一切都是自动的，无需手动编写！**

### 1.4 不同内存类型的拷贝

#### 主机内存拷贝（Host）

```cpp
// 主机端代码
float src[128], dst[128];
auto src_tensor = make_tensor(src, make_shape(Int<128>{}));
auto dst_tensor = make_tensor(dst, make_shape(Int<128>{}));

// 在主机端执行拷贝
copy(src_tensor, dst_tensor);
```

**特点**：
- 在主机端执行
- 使用标准的 C++ 赋值操作
- 编译器可以进行向量化优化

#### 全局内存 → 寄存器（Device）

```cpp
__global__ void copy_kernel(float* gmem) {
    // 全局内存 Tensor
    auto g_tensor = make_tensor(make_gmem_ptr(gmem), make_shape(Int<128>{}));
    
    // 寄存器 Tensor（拥有数据）
    auto r_tensor = make_tensor<float>(Shape<_128>{});
    
    // 拷贝到寄存器
    copy(g_tensor, r_tensor);
    
    // 现在数据在寄存器中，可以高效处理
    // process(r_tensor);
}
```

**优化点**：
- CuTe 可能使用向量化加载（`ld.global.v4`）
- 如果是合并访问，性能最佳

#### 全局内存 → 共享内存（Device）

```cpp
__global__ void copy_kernel(float* gmem) {
    // 全局内存 Tensor（标记类型）
    auto g_tensor = make_tensor(make_gmem_ptr(gmem), make_shape(Int<256>{}));
    
    // 共享内存 Tensor（标记类型）
    __shared__ float smem[256];
    auto s_tensor = make_tensor(make_smem_ptr(smem), make_shape(Int<256>{}));
    
    // 分配给线程
    auto thr_layout = make_layout(Int<256>{});  // 256 个线程
    auto thr_g = local_partition(g_tensor, thr_layout, threadIdx.x);
    auto thr_s = local_partition(s_tensor, thr_layout, threadIdx.x);
    
    // 拷贝（每个线程拷贝一个元素）
    copy(thr_g, thr_s);
    
    // 同步，确保所有线程完成拷贝
    __syncthreads();
}
```

**关键点**：
- 使用 `make_gmem_ptr` 和 `make_smem_ptr` 标记内存类型
- 使用 `local_partition` 分配任务给各个线程
- **必须**在使用数据前调用 `__syncthreads()`

**为什么需要同步？**
- `copy` 可能使用**异步**拷贝指令（如 `cp.async`）
- 单个线程执行的拷贝不需要同步
- 但如果多个线程协作拷贝一个共享的数据结构，必须等待所有线程完成

#### 共享内存 → 寄存器（Device）

```cpp
__global__ void copy_kernel() {
    __shared__ float smem[128];
    
    // 假设 smem 已经被填充数据
    auto s_tensor = make_tensor(make_smem_ptr(smem), make_shape(Int<128>{}));
    
    // 寄存器 Tensor
    auto r_tensor = make_tensor_like(s_tensor);
    
    // 拷贝到寄存器
    copy(s_tensor, r_tensor);
    
    // 处理数据
}
```

**优化点**：
- 向量化加载（`lds.128` 等）
- 避免 shared memory bank conflict（CuTe 可以通过 swizzle 优化）

### 1.5 Copy 的并行性和同步

根据 [CUTLASS 文档](https://docs.nvidia.com/cutlass/media/docs/cpp/cute/04_algorithms.html)，`copy` 的行为（并行性、同步）取决于参数类型。

#### 串行 vs 并行

| 场景 | 并行性 | 说明 |
|------|--------|------|
| **单线程拷贝** | 串行 | 一个线程执行完整的拷贝 |
| **多线程拷贝** | 并行 | 多个线程协作拷贝（使用 partition） |

#### 同步 vs 异步

| 指令类型 | 同步性 | 需要的同步操作 |
|---------|-------|---------------|
| **普通加载/存储** | 同步 | 无（单线程） / `__syncthreads()`（多线程） |
| **cp.async** | 异步 | `cp.async.wait_group` / `cp.async.commit_group` |
| **TMA** | 异步 | TMA 特定的同步机制（后文介绍） |

#### 示例：异步拷贝（cp.async）

```cpp
__global__ void async_copy_kernel(float* gmem) {
    auto g_tensor = make_tensor(make_gmem_ptr(gmem), make_shape(Int<256>{}));
    
    __shared__ float smem[256];
    auto s_tensor = make_tensor(make_smem_ptr(smem), make_shape(Int<256>{}));
    
    auto thr_layout = make_layout(Int<256>{});
    auto thr_g = local_partition(g_tensor, thr_layout, threadIdx.x);
    auto thr_s = local_partition(s_tensor, thr_layout, threadIdx.x);
    
    // 开始异步拷贝
    copy(thr_g, thr_s);
    
    // 如果使用了 cp.async，需要等待完成
    // 方式1：等待所有 cp.async 完成
    cute::cp_async_wait<0>();  // 等待所有组
    __syncthreads();
    
    // 方式2：使用流水线（更高级，后续章节介绍）
    // cp_async_fence();
    // cp_async_wait_group<1>();  // 等待除了最后一组外的所有组
}
```

**关键点**：
- `cp.async` 指令在后台异步执行
- 必须使用 `cp_async_wait` 等待完成
- 然后使用 `__syncthreads()` 确保所有线程都看到数据

#### 如何知道使用了哪种指令？

用户通常**不需要显式知道**，但可以通过以下方式推断：

1. **内存类型标记**：
   - `make_gmem_ptr` + `make_smem_ptr` → 可能使用 `cp.async`
   - 未标记 → 使用普通加载/存储
   
2. **架构**：
   - Ampere (sm_80+) → 支持 `cp.async`
   - Hopper (sm_90+) → 支持 TMA

3. **查看生成的 PTX/SASS**：
   - 使用 `nvcc -ptx` 或 `cuobjdump` 查看生成的指令

**最佳实践**：
- 总是标记内存类型（`make_gmem_ptr` / `make_smem_ptr`）
- 在多线程拷贝后总是调用 `__syncthreads()`
- 如果性能关键，查看生成的汇编代码验证优化

### 1.6 Copy_if（条件拷贝）

`copy_if` 算法根据谓词（predicate）有条件地拷贝元素。

#### 基本接口

```cpp
template <class PredEngine, class PredLayout,
          class SrcEngine, class SrcLayout,
          class DstEngine, class DstLayout>
CUTE_HOST_DEVICE
void
copy_if(Tensor<PredEngine, PredLayout> const& pred,
        Tensor<SrcEngine, SrcLayout> const& src,
        Tensor<DstEngine, DstLayout>      & dst);
```

**注意**：参数顺序是 **`pred, src, dst`**，谓词（predicate）在第一位。

#### 使用示例

```cpp
// 源数据、目标数据、谓词
float src[128];
float dst[128];
bool mask[128];

// 初始化
for (int i = 0; i < 128; ++i) {
    src[i] = i * 1.0f;
    mask[i] = (i % 2 == 0);  // 只拷贝偶数索引
    dst[i] = -1.0f;  // 初始化为 -1
}

// 创建 Tensor
auto src_tensor = make_tensor(src, make_shape(Int<128>{}));
auto dst_tensor = make_tensor(dst, make_shape(Int<128>{}));
auto mask_tensor = make_tensor(mask, make_shape(Int<128>{}));

// 条件拷贝（参数顺序：pred, src, dst）
copy_if(mask_tensor, src_tensor, dst_tensor);

// 验证：只有偶数索引被拷贝
for (int i = 0; i < 128; ++i) {
    if (i % 2 == 0) {
        assert(dst[i] == src[i]);  // 被拷贝
    } else {
        assert(dst[i] == -1.0f);   // 未被拷贝
    }
}
```

#### 应用场景：边界处理

`copy_if` 常用于处理 Tensor 边界，避免越界访问：

```cpp
__global__ void copy_with_boundary_check(float* src, float* dst, int M, int N) {
    // 假设每个 block 处理 16×16 的 tile
    auto g_src = make_tensor(make_gmem_ptr(src), make_shape(M, N));
    auto g_dst = make_tensor(make_gmem_ptr(dst), make_shape(M, N));
    
    // 提取当前 block 的 tile（可能超出边界）
    int block_m = blockIdx.x * 16;
    int block_n = blockIdx.y * 16;
    auto tile_src = local_tile(g_src, make_shape(Int<16>{}, Int<16>{}), 
                               make_coord(block_m, block_n));
    auto tile_dst = local_tile(g_dst, make_shape(Int<16>{}, Int<16>{}), 
                               make_coord(block_m, block_n));
    
    // 生成谓词 Tensor：检查是否在边界内
    auto pred = make_tensor<bool>(Shape<_16, _16>{});
    for (int i = 0; i < 16; ++i) {
        for (int j = 0; j < 16; ++j) {
            pred(i, j) = (block_m + i < M) && (block_n + j < N);
        }
    }
    
    // 只拷贝在边界内的元素（参数顺序：pred, src, dst）
    copy_if(pred, tile_src, tile_dst);
}
```

**优势**：
- 避免复杂的边界检查逻辑
- 代码更简洁
- CuTe 可以优化谓词计算

#### copy_if vs 手动检查

| 方式 | 优点 | 缺点 |
|------|------|------|
| **copy_if** | 代码简洁<br>CuTe 可以优化<br>类型安全 | 需要额外的谓词 Tensor |
| **手动检查** | 灵活<br>可以内联检查 | 代码冗长<br>容易出错 |

**推荐**：对于边界处理等规则的条件拷贝，优先使用 `copy_if`。

### 1.7 Copy_Atom（显式控制拷贝）

#### 什么是 Copy_Atom？

`Copy_Atom` 是 CuTe 中用于显式控制拷贝行为的抽象。它封装了：
- **拷贝操作**：底层的硬件指令（如 `cp.async`、`ldgsts` 等）
- **Copy_Traits**：描述拷贝操作的特性（线程布局、数据布局等）
- **内部类型**：拷贝时使用的数据类型（如 `float`、`uint128_t` 等）

**为什么需要 Copy_Atom？**

在前面的示例中，我们使用 `copy(src, dst)` 让 CuTe 自动选择拷贝实现。但在以下场景中，你可能需要显式控制：

1. **强制使用特定指令**：例如，必须使用 `cp.async.ca`（cache all levels）
2. **控制缓存策略**：不同的缓存策略影响性能
3. **性能调优和实验**：测试不同指令的性能差异
4. **学习和理解底层**：了解 CuTe 如何映射到硬件指令

#### SM80 cp.async 指令类型

Ampere (SM80+) 架构提供了异步拷贝指令，主要包括：

| 拷贝类型 | 指令 | 缓存策略 | 支持的大小 | 适用场景 |
|---------|------|---------|-----------|---------|
| `SM80_CP_ASYNC_CACHEALWAYS` | `cp.async.ca` | 所有级别缓存 | 4/8/16 字节 | 数据会多次访问（如 GEMM）|
| `SM80_CP_ASYNC_CACHEGLOBAL` | `cp.async.cg` | 只缓存全局级别 | 16 字节 | 数据只访问一次（如向量操作）|

**注意**：
- `cp.async.ca`：将数据缓存在所有级别（L1、L2），适合会重复访问的数据
- `cp.async.cg`：只缓存在 L2，不占用 L1 空间，适合流式处理

#### 示例：显式使用 cp.async.ca 拷贝 float 数据

```cpp
#include <cute/tensor.hpp>
#include <cute/atom/copy_atom.hpp>
#include <cute/atom/copy_traits_sm80.hpp>
#include <cute/arch/copy_sm80.hpp>

using namespace cute;

__global__ void kernel_copy_with_cachealways(float* gmem, float* result) {
    __shared__ float smem[128];
    
    // 显式创建 Copy_Atom，指定使用 cp.async.ca
    // uint128_t 表示 16 字节（128 位）的拷贝
    using CopyOp = SM80_CP_ASYNC_CACHEALWAYS<uint128_t>;
    Copy_Atom<Copy_Traits<CopyOp>, float> copy_atom;
    
    // 32 个线程，每个线程拷贝 1 个 uint128_t（4 个 float）
    if (threadIdx.x < 32) {
        int offset = threadIdx.x * 4;
        // 直接创建每个线程的连续张量
        auto thr_g = make_tensor(make_gmem_ptr(&gmem[offset]), make_shape(Int<4>{}));
        auto thr_s = make_tensor(make_smem_ptr(&smem[offset]), make_shape(Int<4>{}));
        
        // 使用显式的 copy_atom 进行拷贝
        copy(copy_atom, thr_g, thr_s);
    }
    
    // 等待异步拷贝完成
    cp_async_fence();
    cp_async_wait<0>();
    __syncthreads();
    
    // 将结果写回全局内存
    if (threadIdx.x < 32) {
        int offset = threadIdx.x * 4;
        for (int i = 0; i < 4; ++i) {
            result[offset + i] = smem[offset + i];
        }
    }
}
```

**代码说明**：
1. **创建 Copy_Atom**：
   ```cpp
   using CopyOp = SM80_CP_ASYNC_CACHEALWAYS<uint128_t>;
   Copy_Atom<Copy_Traits<CopyOp>, float> copy_atom;
   ```
   - `SM80_CP_ASYNC_CACHEALWAYS<uint128_t>`：指定使用 cp.async.ca 指令，16 字节拷贝
   - `Copy_Traits<CopyOp>`：包装 Copy 操作的 traits
   - `float`：张量的元素类型（虽然指令操作 16 字节，但张量是 float 类型）

2. **创建连续张量**：
   ```cpp
   auto thr_g = make_tensor(make_gmem_ptr(&gmem[offset]), make_shape(Int<4>{}));
   auto thr_s = make_tensor(make_smem_ptr(&smem[offset]), make_shape(Int<4>{}));
   ```
   - 每个线程创建一个包含 4 个 float 的连续张量（= 16 字节）
   - 这样张量的布局可以直接映射到 uint128_t 指令

3. **调用 copy**：`copy(copy_atom, thr_g, thr_s)` 使用显式的 copy_atom

4. **同步**：
   - `cp_async_fence()`：标记异步操作的边界
   - `cp_async_wait<0>()`：等待所有异步操作完成
   - `__syncthreads()`：线程同步

**编译和运行**：
```bash
# 编译（需要 SM80+ 架构）
nvcc -std=c++17 -I/path/to/cutlass/include -arch=sm_80 -o 03_copy_atom 03_copy_atom.cu

# 运行
./03_copy_atom
```

**输出示例**：
```
CuTe Copy_Atom 显式控制拷贝示例
==================================
GPU: NVIDIA H100 80GB HBM3
Compute Capability: 9.0
✓ 支持 SM80+ cp.async 指令

=== 使用 cp.async.ca 显式拷贝 float 数据 ===
✓ cp.async.ca 拷贝成功！
  - 32 个线程，每个线程拷贝 4 个 float (16 字节)
  - 使用 uint128_t Copy_Atom 进行向量化拷贝
  - cache all levels 策略适用于会多次访问的数据

测试完成！
```

#### 何时使用显式 Copy_Atom？

| 场景 | 推荐方式 | 原因 |
|------|---------|------|
| **简单拷贝** | `copy(src, dst)` | 自动派发，代码简洁 |
| **需要特定缓存策略** | 显式 Copy_Atom | 精确控制性能 |
| **学习底层实现** | 显式 Copy_Atom | 理解 CuTe 如何映射到硬件 |
| **性能调优** | 显式 Copy_Atom | 测试不同指令的性能 |
| **与 TiledCopy 配合** | 显式 Copy_Atom | 后续章节会详细介绍 |

**推荐**：对于大多数场景，使用 `copy(src, dst)` 即可。只有在需要精确控制或性能调优时才使用显式 Copy_Atom。

---

## 2. Copy 的优化技巧

### 2.1 使用静态 Shape

```cpp
// 慢：动态 shape
auto src = make_tensor(src_ptr, make_shape(128));
auto dst = make_tensor(dst_ptr, make_shape(128));
copy(src, dst);

// 快：静态 shape（编译器可以完全展开）
auto src = make_tensor(src_ptr, make_shape(Int<128>{}));
auto dst = make_tensor(dst_ptr, make_shape(Int<128>{}));
copy(src, dst);
```

**性能提升**：
- 编译器可以展开循环
- 可以进行更激进的优化（如向量化）
- 消除分支

### 2.2 标记内存类型

```cpp
// 未优化：未标记内存类型
auto g_tensor = make_tensor(gmem_ptr, make_shape(Int<256>{}));
auto s_tensor = make_tensor(smem_ptr, make_shape(Int<256>{}));
copy(g_tensor, s_tensor);  // 可能只用普通的 load/store

// 优化：标记内存类型
auto g_tensor = make_tensor(make_gmem_ptr(gmem_ptr), make_shape(Int<256>{}));
__shared__ float smem[256];
auto s_tensor = make_tensor(make_smem_ptr(smem), make_shape(Int<256>{}));
copy(g_tensor, s_tensor);  // 可能使用 cp.async
```

**性能提升**：
- 启用异步拷贝（`cp.async`）
- 减少寄存器压力（异步拷贝不占用寄存器）
- 可以与计算重叠

### 2.3 对齐和向量化

```cpp
// 确保数据对齐到 16 字节（128 位）
alignas(16) float src[128];
alignas(16) float dst[128];

// 使用向量化类型
auto src = make_tensor(make_gmem_ptr<float4>(src_ptr), make_shape(Int<32>{}));
auto dst = make_tensor(make_gmem_ptr<float4>(dst_ptr), make_shape(Int<32>{}));
copy(src, dst);  // 每次拷贝 4 个 float
```

**性能提升**：
- 一条指令加载/存储多个元素
- 提高内存带宽利用率
- 减少指令数量

### 2.4 使用 Partition 进行并行拷贝

```cpp
__global__ void parallel_copy(float* src, float* dst) {
    auto g_src = make_tensor(make_gmem_ptr(src), make_shape(Int<1024>{}));
    auto g_dst = make_tensor(make_gmem_ptr(dst), make_shape(Int<1024>{}));
    
    // 256 个线程并行拷贝
    auto thr_layout = make_layout(Int<256>{});
    auto thr_src = local_partition(g_src, thr_layout, threadIdx.x);
    auto thr_dst = local_partition(g_dst, thr_layout, threadIdx.x);
    
    // 每个线程拷贝 4 个元素（1024 / 256 = 4）
    copy(thr_src, thr_dst);
}
```

**性能提升**：
- 利用多个线程的并行性
- 实现合并访问（coalesced access）
- 提高内存带宽利用率

---

## 3. 常见错误和解决方案

### 错误 1：Shape 不匹配

```cpp
// 错误
auto src = make_tensor(src_ptr, make_shape(Int<128>{}));
auto dst = make_tensor(dst_ptr, make_shape(Int<64>{}));
copy(src, dst);  // 编译错误或运行时错误
```

**解决方案**：确保 shape 兼容。

```cpp
// 正确
auto dst = make_tensor(dst_ptr, make_shape(Int<128>{}));
copy(src, dst);  // OK
```

### 错误 2：忘记同步

```cpp
// 错误
__global__ void kernel(float* gmem) {
    auto g_tensor = make_tensor(make_gmem_ptr(gmem), make_shape(Int<256>{}));
    __shared__ float smem[256];
    auto s_tensor = make_tensor(make_smem_ptr(smem), make_shape(Int<256>{}));
    
    auto thr_g = local_partition(g_tensor, make_layout(Int<256>{}), threadIdx.x);
    auto thr_s = local_partition(s_tensor, make_layout(Int<256>{}), threadIdx.x);
    
    copy(thr_g, thr_s);
    // 忘记同步，直接使用 s_tensor！
    float value = s_tensor(0);  // 可能读到未完成的数据
}
```

**解决方案**：在多线程拷贝后添加同步。

```cpp
// 正确
copy(thr_g, thr_s);
__syncthreads();  // 等待所有线程完成
float value = s_tensor(0);  // OK
```

### 错误 3：异步拷贝未等待

```cpp
// 错误：使用 cp.async 但未等待
copy(gmem_tensor, smem_tensor);  // 可能使用 cp.async
__syncthreads();  // 不够！cp.async 可能还没完成
float value = smem_tensor(0);  // 可能读到旧数据
```

**解决方案**：显式等待异步拷贝完成。

```cpp
// 正确
copy(gmem_tensor, smem_tensor);
cute::cp_async_wait<0>();  // 等待所有 cp.async 组
__syncthreads();
float value = smem_tensor(0);  // OK
```

### 错误 4：未对齐的向量化访问

```cpp
// 错误：未对齐的指针
float* unaligned_ptr = ptr + 1;  // 未对齐到 16 字节
auto tensor = make_tensor(make_gmem_ptr<float4>(unaligned_ptr), make_shape(Int<32>{}));
copy(tensor, dst);  // 可能崩溃或性能差
```

**解决方案**：确保指针对齐。

```cpp
// 正确：确保对齐
alignas(16) float data[128];
float* aligned_ptr = data;
auto tensor = make_tensor(make_gmem_ptr<float4>(aligned_ptr), make_shape(Int<32>{}));
copy(tensor, dst);  // OK
```

---

## 4. 实践任务

以下任务对应本教程的示例代码，建议按顺序完成：

### 任务 1：基本 Copy（`01_basic_copy.cu`）

实现一个 CUDA kernel，将全局内存的数据拷贝到共享内存：

**要求**：
- 拷贝 1024 个 float 从全局内存到共享内存
- 使用 256 个线程并行拷贝
- 使用 `local_partition` 为每个线程分配任务
- 使用 `make_gmem_ptr` 和 `make_smem_ptr` 标记内存类型
- 正确使用 `__syncthreads()` 同步
- 验证拷贝结果的正确性

---

### 任务 2：条件拷贝（`02_copy_if.cu`）

实现一个 kernel，只拷贝满足条件的元素：

**要求**：
- 从 256 个 float 中只拷贝正数（值 > 0）
- 使用 `copy_if` 函数
- 动态生成谓词 Tensor（使用 `make_tensor` 包装 bool 数组）
- 验证只有满足条件的元素被拷贝
- 对比 `copy_if` 和手动 if 检查的性能

---

### 任务 3：使用 Copy_Atom 显式控制拷贝（`03_copy_atom.cu`）

实现一个 kernel，使用显式的 `Copy_Atom` 进行异步拷贝（需要 SM80+）：

**要求**：
- 拷贝 128 个 float 从全局内存到共享内存
- 创建 `Copy_Atom<Copy_Traits<SM80_CP_ASYNC_CACHEALWAYS<uint128_t>>, float>`
- 使用 32 个线程，每个线程拷贝 4 个 float（16 字节）
- 为每个线程创建连续的张量（`make_shape(Int<4>{})`）
- 正确使用 `cp_async_fence()` 和 `cp_async_wait<0>()`
- 验证拷贝结果的正确性



