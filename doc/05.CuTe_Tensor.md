# CuTe Tensor（张量）

> CuTe Tensor 是 CuTe 中最核心的抽象，它将指针（Pointer）和布局（Layout）结合在一起，提供了一个强大而灵活的多维数组接口。学会 Tensor 后，你将能够优雅地处理复杂的数据访问模式，而不用关心底层的指针运算细节。
>
> **配套代码示例**：[code/05_cute_tensor](../code/05_cute_tensor)
>

## 环境要求
+ CUTLASS 3.x
+ NVCC with C++ 17

## 核心概念

### Tensor 是什么？

**Tensor = Engine + Layout**

这是 CuTe 中最重要的公式！一个 Tensor 由两部分组成：
- **Engine（引擎）**：封装了指向数据的迭代器，提供数据存储
- **Layout（布局）**：描述如何访问这些数据（形状和步长）

Tensor 使用 Layout 计算坐标到偏移量的映射，然后通过 Engine 持有的迭代器访问实际数据。

### Tensor Engine

Engine 是迭代器或数据数组的包装器，它使用类似 `std::array` 的精简接口：

```cpp
using iterator   = ...  // 迭代器类型
using value_type = ...  // 值类型
using reference  = ...  // 引用类型
iterator begin()        // 返回迭代器
```

**常见的 Engine 类型**：
- **ArrayEngine<T,N>**：拥有数据的 Engine（类似 `std::array`）
- **ViewEngine<Iter>**：非拥有的视图 Engine（类似指针）
- **ConstViewEngine<Iter>**：只读视图 Engine

通常不需要手动构造 Engine，`make_tensor` 会自动选择合适的 Engine 类型。

### 生活中的类比

想象你有一个仓库（内存）：
- **Pointer** 就像仓库的地址（"在某某街123号"）
- **Layout** 就像仓库的货架布局图（"5排，每排8个货位"）
- **Tensor** = 地址 + 布局图 = 你可以精确找到任何货物

### 为什么需要 Tensor？

| 传统方式 | CuTe Tensor |
|---------|------------|
| `float* ptr = ...;`<br>`int idx = i*N + j;`<br>`ptr[idx]` | `auto tensor = make_tensor(ptr, layout);`<br>`tensor(i, j)` |
| 容易出错<br>可读性差<br>难以维护 | 类型安全<br>可读性强<br>易于重构 |

### CuTe Tensor 的关键特性

1. **内存抽象统一**：全局内存、共享内存、寄存器使用统一接口
2. **内存类型标记**：通过 `make_gmem_ptr()` / `make_smem_ptr()` 标记内存类型，让 CuTe 自动选择最优指令
3. **形状推导**：`make_tensor_like()` 自动推导形状，减少错误
4. **编译期优化**：使用静态 Shape（`Int<N>`）实现零开销抽象

---

## 创建 Tensor

### 方式 1：从指针和布局创建

```cpp
// 有一块内存
float data[24];

// 创建布局：4×6 矩阵（列主序）
auto layout = make_layout(make_shape(Int<4>{}, Int<6>{}));

// 创建 Tensor
auto tensor = make_tensor(data, layout);

// 现在可以用坐标访问
tensor(0, 0) = 1.0f;  // 第一个元素
tensor(2, 3) = 5.0f;  // 第3行第4列
```

**解释**：
- `data` 是原始指针
- `layout` 定义了如何解释这块内存
- `tensor` 将两者结合，提供友好的访问接口

### 方式 2：使用 make_tensor 的便捷形式

```cpp
// 直接指定 shape
float data[24];
auto tensor = make_tensor(data, make_shape(Int<4>{}, Int<6>{}));
// 默认使用列主序布局

// 指定 shape 和 stride
auto tensor2 = make_tensor(data, 
                          make_shape(Int<4>{}, Int<6>{}),
                          make_stride(Int<6>{}, Int<1>{}));
// 行主序布局
```

### 方式 3：标记内存类型（Tagged Pointers）

CuTe 允许你"标记"指针的内存空间类型，这使得 CuTe 能够为特定类型的内存选择最优的实现。

```cpp
float* gmem_ptr = ...;
__shared__ float smem[128];

// 标记为全局内存指针
auto gmem_tensor = make_tensor(make_gmem_ptr(gmem_ptr), make_shape(Int<128>{}));
// 或者显式指定类型
auto gmem_tensor2 = make_tensor(make_gmem_ptr<float>(gmem_ptr), make_shape(Int<128>{}));

// 标记为共享内存指针
auto smem_tensor = make_tensor(make_smem_ptr(smem), make_shape(Int<128>{}));
// 或者显式指定类型
auto smem_tensor2 = make_tensor(make_smem_ptr<float>(smem), make_shape(Int<128>{}));

// 混合使用：静态和动态大小
auto gmem_mixed = make_tensor(make_gmem_ptr(gmem_ptr), 
                             make_shape(Int<8>{}, 16));  // 第一维静态，第二维动态
```

**为什么要标记内存类型？**

| 优势 | 说明 |
|------|------|
| **性能优化** | CuTe 可以针对不同内存类型使用最优的访问指令 |
| **类型安全** | 编译期验证内存类型是否符合特定操作的要求 |
| **自动派发** | 某些拷贝操作（如 cp.async）需要特定的内存类型组合 |

**示例：利用标记优化拷贝**

```cpp
// 全局内存到共享内存的拷贝
auto g_tensor = make_tensor(make_gmem_ptr(global_ptr), make_shape(Int<128>{}));
auto s_tensor = make_tensor(make_smem_ptr(shared_ptr), make_shape(Int<128>{}));

// CuTe 会自动选择最优的拷贝方式（如 cp.async）
copy(g_tensor, s_tensor);
```

### 方式 4：使用 make_tensor_like 创建拥有数据的 Tensor

`make_tensor_like` 创建一个**拥有数据的 Tensor**，它：
- 匹配输入 Tensor 的 **value type**（元素类型）
- 匹配输入 Tensor 的 **shape**（形状）
- 尝试使用相同的 **stride 顺序**
- **自动分配存储空间**（类似 `std::array`）

```cpp
// 有一个全局内存的 Tensor
float* gmem = ...;
auto gmem_tensor = make_tensor(make_gmem_ptr(gmem), make_shape(Int<8>{}, Int<16>{}));

// 创建形状相同的拥有型 Tensor（会自动分配存储空间）
auto rmem_row = make_tensor_like(gmem_tensor(_, 0));  // 形状: (_8)

// rmem_row 是拥有数据的 Tensor：
// - 自动分配了存储空间
// - 在主机端：类似 std::array
// - 在设备端（kernel）：分配寄存器
// - 匹配了 value type (float) 和 shape (_8)

// 可以直接使用
for (int i = 0; i < size(rmem_row); ++i) {
    rmem_row(i) = gmem_tensor(i, 0);  // 拷贝数据
}
```

**make_tensor_like 的常见用法**

```cpp
// 场景 1：创建寄存器缓冲区（自动分配存储）
auto gmem = make_tensor(make_gmem_ptr(ptr), make_shape(Int<128>{}));
auto rmem = make_tensor_like(gmem);  // 自动分配 128 个元素的存储

// 场景 2：创建与子视图相同形状的 Tensor
auto matrix = make_tensor(ptr, make_shape(Int<8>{}, Int<16>{}));
auto column = matrix(_, 3);           // 取第4列，形状: (_8)
auto rmem_col = make_tensor_like(column);  // 自动分配 8 个元素的存储

// 场景 3：处理分块数据
auto tiled = zipped_divide(gmem, make_shape(Int<4>{}, Int<8>{}));
auto tile = tiled(make_coord(_,_), make_coord(0,0));  // 取第一个 tile
auto rmem_tile = make_tensor_like(tile);  // 自动分配与 tile 相同大小的存储
```

**为什么使用 make_tensor_like？**

| 优势 | 说明 |
|------|------|
| **自动分配存储** | 无需手动分配数组或寄存器空间 |
| **类型安全** | 自动匹配源 Tensor 的元素类型 |
| **形状一致** | 保证形状完全匹配，避免尺寸错误 |
| **保留布局特性** | 尝试使用相同的 stride 顺序 |
| **代码简洁** | 一行代码完成创建和分配 |
| **泛型编程** | 在模板函数中无需关心具体形状和大小 |

**重要说明**：
- `make_tensor_like` 创建的是**拥有数据的 Tensor**（owning tensor）
- 在主机端，它像 `std::array` 一样拥有数据
- 在设备端（kernel 中），它会分配寄存器来存储数据
- 不需要传入指针，它自动管理存储
- 它会尝试匹配源 Tensor 的 stride 顺序（如行主序/列主序）

### 方式 5：从现有 Tensor 的视图创建

```cpp
// 原始 tensor
auto tensor = make_tensor(data, make_shape(Int<8>{}, Int<8>{}));

// 取一个子区域（前4行4列）
auto sub_tensor = local_tile(tensor, make_shape(Int<4>{}, Int<4>{}), make_coord(0, 0));
```

### Owning vs Nonowning Tensors

根据[官方文档](https://docs.nvidia.com/cutlass/media/docs/cpp/cute/03_tensor.html)，Tensor 可以是**拥有数据**（owning）或**不拥有数据**（nonowning）的。

#### Nonowning Tensors（非拥有型，默认）

大多数情况下，Tensor 是对已有内存的**非拥有视图**：

```cpp
float data[128];
auto tensor = make_tensor(data, make_shape(Int<128>{}));  // 非拥有

// 特点：
// - 类似原始指针的行为
// - 拷贝 Tensor 不会拷贝元素
// - 销毁 Tensor 不会释放内存
```

**函数参数传递建议**：
- 应该通过**引用**或 **const 引用**传递 Tensor
- 按值传递可能会也可能不会深拷贝元素（取决于 Engine 类型）

```cpp
// ✅ 推荐：按引用传递
void process(Tensor<Engine, Layout>& tensor);
void process(const Tensor<Engine, Layout>& tensor);

// ⚠️ 不推荐：按值传递（行为不明确）
void process(Tensor<Engine, Layout> tensor);
```

#### Owning Tensors（拥有型）

拥有数据的 Tensor 通过 `make_tensor<T>` 创建，其中 `T` 是元素类型。内存分配方式类似 `std::array<T,N>`。

**重要限制**：
- **必须使用静态 shape 和静态 stride**
- CuTe **不进行动态内存分配**（在 CUDA kernel 中动态分配不常见且性能差）

**创建方式 1：使用 `make_tensor<T>`**

```cpp
// 寄存器内存（只能使用静态 layout）
// 列主序（默认）
auto rmem_4x8_col = make_tensor<float>(Shape<_4,_8>{});

// 行主序
auto rmem_4x8_row = make_tensor<float>(Shape<_4,_8>{}, LayoutRight{});

// 自定义 stride（带 padding）
auto rmem_4x8_pad = make_tensor<float>(Shape <_4, _8>{},
                                       Stride<_32,_2>{});
```

**创建方式 2：使用 `make_tensor_like`**

`make_tensor_like` 创建一个拥有数据的 Tensor，它：
- 匹配输入 Tensor 的 **value type** 和 **shape**
- 尝试使用相同的 **stride 顺序**

```cpp
auto rmem_4x8_like = make_tensor_like(rmem_4x8_pad);
// 自动匹配类型、形状和 stride 顺序
```

**验证独立性**：

使用 `print` 可以看到每个拥有型 Tensor 都有唯一的指针地址，表明它们是独立的内存分配：

```cpp
print(rmem_4x8_col);   // ptr[32b](0x7fff48929460) o (_4,_8):(_1,_4)
print(rmem_4x8_row);   // ptr[32b](0x7fff489294e0) o (_4,_8):(_8,_1)
print(rmem_4x8_pad);   // ptr[32b](0x7fff489295e0) o (_4,_8):(_32,_2)
print(rmem_4x8_like);  // ptr[32b](0x7fff48929560) o (_4,_8):(_8,_1)
```

注意：每个 Tensor 的指针地址不同，说明它们各自拥有独立的内存。

**特点总结**：
- 类似 `std::array` 的行为
- 拷贝 Tensor 会深拷贝所有元素
- 销毁 Tensor 会释放内存
- 只能用于静态大小（`Int<N>`）
- 主要用于寄存器内存分配

| 特性 | Nonowning Tensor | Owning Tensor |
|------|-----------------|---------------|
| **创建方式** | `make_tensor(ptr, layout)` | `make_tensor<T>(layout)`<br>`make_tensor_like(tensor)` |
| **数据所有权** | 不拥有 | 拥有 |
| **拷贝行为** | 浅拷贝（只拷贝指针） | 深拷贝（拷贝所有元素） |
| **销毁行为** | 不释放内存 | 释放内存 |
| **Layout 要求** | 静态或动态 | 必须静态（`Int<N>`） |
| **内存分配** | 无（使用已有内存） | 类似 `std::array` |
| **适用场景** | 视图、引用已有数据 | 寄存器缓冲区、局部存储 |

### 静态 vs 动态 Tensor

| 特性 | 静态 Tensor | 动态 Tensor |
|------|------------|------------|
| **Shape 类型** | `Int<N>` | `int` |
| **编译期优化** | 完全优化 | 有限优化 |
| **灵活性** | 编译时固定 | 运行时可变 |
| **性能** | 最高 | 较高 |
| **适用场景** | Tile大小、Block大小 | 用户输入、动态分配 |

```cpp
// 静态 Tensor（推荐用于性能关键代码）
auto static_tensor = make_tensor(ptr, make_shape(Int<128>{}, Int<128>{}));

// 动态 Tensor（适用于运行时确定的大小）
int m = 128, n = 128;
auto dynamic_tensor = make_tensor(ptr, make_shape(m, n));

// 混合使用
auto hybrid_tensor = make_tensor(ptr, make_shape(Int<128>{}, n));
// 第一维静态，第二维动态
```

---

## 访问 Tensor 元素

### 基本访问

Tensor 提供了两种访问元素的方式：`operator[]` 和 `operator()`。

```cpp
auto tensor = make_tensor(ptr, make_shape(Int<4>{}, Int<6>{}));

// 方式 1：使用 operator()（推荐）
float value = tensor(2, 3);     // 多维坐标
tensor(1, 4) = 3.14f;

// 方式 2：使用 operator[]
float value2 = tensor[make_coord(2, 3)];  // 需要显式 make_coord
tensor[make_coord(1, 4)] = 3.14f;

// 一维索引访问（按列序遍历）
tensor(0) = 1.0f;   // 等价于 tensor(0, 0)
tensor(1) = 2.0f;   // 等价于 tensor(1, 0)
tensor(4) = 3.0f;   // 等价于 tensor(0, 1)
```

**operator() vs operator[]**：
- `operator()`：接受多个参数，使用更方便
- `operator[]`：接受单个 Coord 对象
- 推荐使用 `operator()`，因为语法更简洁

### Tensor 的基本操作

根据[官方文档](https://docs.nvidia.com/cutlass/media/docs/cpp/cute/03_tensor.html)，Tensor 提供以下基本操作：

```cpp
auto tensor = make_tensor(ptr, make_shape(Int<4>{}, Int<6>{}));

// 数据访问
auto ptr = tensor.data();           // 获取底层迭代器
auto total_size = tensor.size();    // 总元素数

// 坐标访问
tensor(i, j);                       // 多维坐标
tensor[coord];                      // Coord 对象
tensor(make_coord(i, j));          // 显式 Coord
```

### 多种坐标形式

```cpp
// 假设 tensor 的 shape 是 (4, (2, 3))
auto tensor = make_tensor(ptr, 
    make_shape(Int<4>{}, make_shape(Int<2>{}, Int<3>{})));

// 方式 1：一维索引
tensor(5);

// 方式 2：扁平坐标
tensor(1, 1);

// 方式 3：层次化坐标
tensor(make_coord(1, make_coord(0, 1)));

// 这三种方式访问的是同一个元素！
```

### 遍历 Tensor

```cpp
auto tensor = make_tensor(ptr, make_shape(Int<4>{}, Int<6>{}));

// 方式 1：使用一维索引
for (int i = 0; i < size(tensor); ++i) {
    tensor(i) = i;
}

// 方式 2：使用多维坐标
for (int i = 0; i < size<0>(tensor); ++i) {
    for (int j = 0; j < size<1>(tensor); ++j) {
        tensor(i, j) = i * 10 + j;
    }
}

// 方式 3：使用 for_each（CuTe 风格）
for_each(tensor, [](auto& x) { x = 0; });
```

---

## Tensor 操作

### 获取 Tensor 属性

Tensor 提供了与 Layout 类似的层次化操作接口，可以查询任意维度的属性。

```cpp
auto tensor = make_tensor(ptr, make_shape(Int<4>{}, Int<6>{}));

// 形状相关
auto s = shape(tensor);          // 返回 shape: (_4, _6)
auto s0 = size<0>(tensor);       // 第一维大小: 4
auto s1 = size<1>(tensor);       // 第二维大小: 6
auto total = size(tensor);       // 总元素数: 24
auto r = rank(tensor);           // 维度数: 2
auto d = depth(tensor);          // 深度

// 步长相关
auto stride = stride(tensor);    // 返回 stride
auto str0 = stride<0>(tensor);   // 第一维步长

// 布局相关
auto layout = layout(tensor);    // 返回 Layout
auto cosize = cosize(tensor);    // cosize

// 指针相关
auto ptr = tensor.data();        // 获取原始指针

// 提取子 tensor（层次化）
auto sub = tensor<0>(tensor);    // 获取第 0 维对应的 subtensor
```

**编译期验证**：

根据[官方文档](https://docs.nvidia.com/cutlass/media/docs/cpp/cute/03_tensor.html)，可以使用 `CUTE_STATIC_ASSERT_V` 在编译期验证 Tensor 的属性：

```cpp
auto tensor = make_tensor(ptr, make_shape(Int<4>{}, Int<6>{}));

// 编译期检查：确保是 2D tensor
CUTE_STATIC_ASSERT_V(rank(tensor) == Int<2>{});

// 编译期检查：确保第一维是静态大小
CUTE_STATIC_ASSERT_V(is_static<decltype(shape<0>(tensor))>{});

// 这些检查在编译期进行，零运行时开销
```

这种编译期验证对泛型编程特别有用，可以确保模板参数满足特定要求。

### Slice（切片）

切片可以固定某些维度，获得降维的视图。

```cpp
// 2D Tensor: 4×6
auto tensor = make_tensor(ptr, make_shape(Int<4>{}, Int<6>{}));

// 固定第二维为 3，得到第4列（1D Tensor）
auto col3 = tensor(_, 3);
// shape: (_4), 访问 col3(i) 等价于 tensor(i, 3)

// 固定第一维为 2，得到第3行（1D Tensor）
auto row2 = tensor(2, _);
// shape: (_6), 访问 row2(j) 等价于 tensor(2, j)

// 多维切片
auto tensor3d = make_tensor(ptr, make_shape(Int<4>{}, Int<6>{}, Int<8>{}));
auto slice = tensor3d(_, 2, _);
// shape: (_4, _8)，固定了中间维度
```

**注意**：`_` 是 CuTe 提供的占位符，表示"保留这个维度"。

### Partition（分区）

分区将 Tensor 按照某种模式分成多个部分，这是 CuTe 中最强大的功能之一。

#### 基本分区

```cpp
// 有 128 个元素
auto tensor = make_tensor(ptr, make_shape(Int<128>{}));

// 分给 32 个线程（1 个 warp）
auto thr_layout = make_layout(Int<32>{});
auto partitioned = local_partition(tensor, thr_layout, threadIdx.x);

// 每个线程得到 4 个元素（128 ÷ 32 = 4）
// partitioned 的 shape: (_4)
```

**解释**：
- `local_partition` 根据线程 ID 将数据分配给各个线程
- 第 0 号线程得到元素 0-3
- 第 1 号线程得到元素 4-7
- ...依此类推

#### 2D 分区

```cpp
// 16×16 的矩阵
auto tensor = make_tensor(ptr, make_shape(Int<16>{}, Int<16>{}));

// 8 个线程的布局
auto thr_layout = make_layout(Int<8>{});

// 分区
auto partitioned = local_partition(tensor, thr_layout, threadIdx.x);

// 每个线程得到 32 个元素 (256 ÷ 8 = 32)
// partitioned 可能是 shape: (_2, _16) 或其他形式，取决于分区策略
```

#### Tiled Partition（平铺分区）

```cpp
// 32×32 矩阵
auto tensor = make_tensor(ptr, make_shape(Int<32>{}, Int<32>{}));

// 每个 tile 是 8×8
auto tile_shape = make_shape(Int<8>{}, Int<8>{});

// 创建 tiled tensor
auto tiled = zipped_divide(tensor, tile_shape);
// 结果 shape: ((8,8), (4,4))
// 前半部分 (8,8) 是单个 tile，后半部分 (4,4) 是 tile 的网格

// 然后可以分配给线程
auto thr_layout = make_layout(make_shape(Int<4>{}, Int<4>{}));
auto per_thread = local_partition(tiled, thr_layout, thread_id);
```

### Local Tile（局部切片）

提取 Tensor 的一个连续子区域。

```cpp
// 64×64 矩阵
auto tensor = make_tensor(ptr, make_shape(Int<64>{}, Int<64>{}));

// 提取 16×16 的子块，从 (8, 16) 开始
auto tile = local_tile(tensor, 
                      make_shape(Int<16>{}, Int<16>{}),  // tile 大小
                      make_coord(8, 16));                 // 起始坐标

// tile 的 shape: (16, 16)
// tile(0, 0) 对应 tensor(8, 16)
// tile(15, 15) 对应 tensor(23, 31)
```

### Inner Partition vs Outer Partition

根据[官方文档](https://docs.nvidia.com/cutlass/media/docs/cpp/cute/03_tensor.html)，分区有两种模式：内分区和外分区。

#### Inner Partition（内分区）

**保留内部的 tile 模式**，索引到外部的 remainder 模式。

```cpp
// 6×8 的矩阵
auto A = make_tensor(ptr, make_shape(Int<6>{}, Int<8>{}));  // (6,8)

// 定义 4×8 的 tiler
auto tiler = make_shape(Int<4>{}, Int<8>{});

// 平铺分割
auto tiled_a = zipped_divide(A, tiler);  // ((4,8), (2,1))
// 结果：(tile_shape, remainder_shape)

// Inner partition：使用 threadgroup 坐标索引 remainder
auto cta_a = tiled_a(make_coord(_, _), make_coord(blockIdx.x, 0));  // (4,8)
// 保留了 tile 的形状

// 等价于 inner_partition 或 local_tile
auto cta_a2 = inner_partition(A, tiler, make_coord(blockIdx.x, 0));
auto cta_a3 = local_tile(A, tiler, make_coord(blockIdx.x, 0));
```

**用途**：通常用于 **threadgroup 级别**的分区，给每个 block 分配一个完整的 tile。

#### Outer Partition（外分区）

**保留外部的 remainder 模式**，索引到内部的 tile 模式。

```cpp
// 接上例
auto tiled_a = zipped_divide(A, tiler);  // ((4,8), (2,1))

// Outer partition：使用线程 ID 索引 tile
auto thr_a = tiled_a(threadIdx.x, make_coord(_, _));  // (2,1)
// 保留了 remainder 的形状

// 等价于 outer_partition
auto thr_a2 = outer_partition(A, tiler, threadIdx.x);
```

**用途**：给每个线程分配 tile 中的**一个元素**（或多个元素）。

#### local_partition 的双重含义

`local_partition` 根据参数类型自动选择：

```cpp
// 版本 1：传入 Layout 和线程 ID（外分区行为）
auto thr_layout = make_layout(make_shape(Int<8>{}, Int<8>{}));
auto partitioned = local_partition(tensor, thr_layout, threadIdx.x);
// 等价于 outer_partition

// 版本 2：传入 Shape/Tile 和坐标（内分区行为）
auto partitioned = local_partition(tensor, tile_shape, coord);
// 等价于 inner_partition / local_tile
```

**对比总结**：

| 分区方式 | 索引位置 | 保留什么 | 典型用途 |
|---------|---------|---------|---------|
| **Inner Partition** | 索引 remainder | 保留 tile 形状 | Block/Threadgroup 分区 |
| **Outer Partition** | 索引 tile | 保留 remainder 形状 | Thread 分区 |

**示例场景**：
```cpp
// 1. Inner partition：每个 block 得到一个 16×16 的 tile
auto block_tile = local_tile(matrix, make_shape(Int<16>{}, Int<16>{}), 
                            make_coord(blockIdx.x, blockIdx.y));

// 2. Outer partition：32 个线程分割这个 tile
auto thread_data = local_partition(block_tile, make_layout(Int<32>{}), threadIdx.x);
```

### Thread-Value Partitioning（线程-值分区）

Thread-Value (TV) partitioning 是[官方文档](https://docs.nvidia.com/cutlass/media/docs/cpp/cute/03_tensor.html)中介绍的一种重要分区策略，用于描述**所有线程**和**每个线程的所有值**到目标数据坐标的映射。

#### 核心思想

构造一个 Layout 来表示：
- **线程维度（Thread）**：有多少个线程
- **值维度（Value）**：每个线程处理多少个值
- 映射到目标数据的坐标

然后使用 `composition` 将目标数据布局转换，最后用线程 ID 切片。

#### 示例

```cpp
// 构造一个 TV-layout：8 个线程，每个线程 4 个值
// 映射到 4×8 tensor 的坐标
// (T8, V4) -> (M4, N8)
auto tv_layout = Layout<Shape <Shape <_2,_4>, Shape <_2, _2>>,
                        Stride<Stride<_8,_1>, Stride<_4,_16>>>{};  // (8,4)

// 有一个 4×8 的 tensor（任意 layout）
auto A = make_tensor<float>(Shape<_4,_8>{}, LayoutRight{});  // (4,8)

// 用 TV-layout 转换 tensor
auto tv = composition(A, tv_layout);  // (8,4)
// 现在 tv 的第一维是线程，第二维是每个线程的值

// 每个线程切片得到自己的数据
auto v = tv(threadIdx.x, _);  // (4)
// 线程 threadIdx.x 得到 4 个值
```

#### 可视化理解

```
原始数据（4×8）:          TV-layout 转换后（8×4）:
+--+--+--+--+--+--+--+--+   Thread 0: [v0][v1][v2][v3]
|  |  |  |  |  |  |  |  |   Thread 1: [v0][v1][v2][v3]
+--+--+--+--+--+--+--+--+   Thread 2: [v0][v1][v2][v3]
|  |  |  |  |  |  |  |  |   ...
+--+--+--+--+--+--+--+--+   Thread 7: [v0][v1][v2][v3]
|  |  |  |  |  |  |  |  |
+--+--+--+--+--+--+--+--+   每行是一个线程的 4 个值
|  |  |  |  |  |  |  |  |
+--+--+--+--+--+--+--+--+
```

#### 应用场景

TV-partitioning 常用于：
- **矩阵乘法（GEMM）**：定义线程如何加载和处理矩阵元素
- **MMA (Matrix Multiply-Accumulate)**：描述 warp 中线程的数据分布
- **Tensor Core 操作**：精确控制数据到线程的映射

#### 与普通 Partition 的对比

| 方式 | 特点 | 适用场景 |
|------|------|---------|
| **普通 Partition** | 简单分割数据 | 规则的数据分配 |
| **TV-Partition** | 精确控制映射模式 | 复杂的访问模式、硬件特定优化 |

**关键区别**：TV-partitioning 通过 composition 转换数据布局，可以实现任意复杂的线程-数据映射模式。

### Reshape（重塑）

改变 Tensor 的形状（但不改变数据布局）。

```cpp
// 24 个元素的一维 Tensor
auto tensor = make_tensor(ptr, make_shape(Int<24>{}));

// 重塑为 4×6 矩阵
auto reshaped = reshape(tensor, make_shape(Int<4>{}, Int<6>{}));
// reshaped 的 shape: (4, 6)

// 重塑为 2×3×4 的三维 Tensor
auto tensor3d = reshape(tensor, make_shape(Int<2>{}, Int<3>{}, Int<4>{}));
// tensor3d 的 shape: (2, 3, 4)
```

**前提条件**：
- 新旧 shape 的 size 必须相同
- 新 shape 必须与旧 shape 兼容（参考布局兼容性）

---

## Tensor 算法

CuTe 提供了一系列高效的 Tensor 算法，用于常见的数据操作。

### Copy（拷贝）

```cpp
// 源 Tensor 和目标 Tensor
auto src = make_tensor(src_ptr, make_shape(Int<128>{}));
auto dst = make_tensor(dst_ptr, make_shape(Int<128>{}));

// 拷贝
copy(src, dst);
// 将 src 的所有元素拷贝到 dst
```

#### Copy 的不同形式

```cpp
// 1. 标量赋值
auto tensor = make_tensor(ptr, make_shape(Int<128>{}));
copy(5.0f, tensor);  // 所有元素设为 5.0

// 2. Tensor 到 Tensor
copy(src_tensor, dst_tensor);

// 3. 部分拷贝
copy(src(_, make_coord(0, 8)), dst(_, make_coord(0, 8)));
// 只拷贝指定范围
```

#### Copy_if（条件拷贝）

```cpp
auto src = make_tensor(src_ptr, make_shape(Int<128>{}));
auto dst = make_tensor(dst_ptr, make_shape(Int<128>{}));
auto mask = make_tensor(mask_ptr, make_shape(Int<128>{}));

// 只拷贝 mask 为 true 的元素
copy_if(src, dst, mask);
```

### Fill（填充）

```cpp
auto tensor = make_tensor(ptr, make_shape(Int<4>{}, Int<6>{}));

// 用常量填充
fill(tensor, 0.0f);  // 所有元素设为 0

// 用序列填充
for (int i = 0; i < size(tensor); ++i) {
    tensor(i) = i;
}
```

### Clear（清零）

```cpp
auto tensor = make_tensor(ptr, make_shape(Int<128>{}));

// 清零（相当于 fill(tensor, 0)）
clear(tensor);
```

### GEMM（矩阵乘法）

```cpp
// A: M×K，B: K×N，C: M×N
auto A = make_tensor(A_ptr, make_shape(Int<M>{}, Int<K>{}));
auto B = make_tensor(B_ptr, make_shape(Int<K>{}, Int<N>{}));
auto C = make_tensor(C_ptr, make_shape(Int<M>{}, Int<N>{}));

// C = A * B
gemm(A, B, C);
```

**注意**：这里的 `gemm` 是概念性的，实际 CUTLASS 中的 GEMM 实现会更复杂，涉及 Tile、Shared Memory、Tensor Core 等。

---

## 实际应用场景

### 场景 1：GEMM 分块计算

```cpp
__global__ void gemm_kernel(float* A, float* B, float* C, int M, int N, int K) {
    // 创建全局 Tensor
    auto gA = make_tensor(make_gmem_ptr(A), make_shape(M, K));
    auto gB = make_tensor(make_gmem_ptr(B), make_shape(K, N));
    auto gC = make_tensor(make_gmem_ptr(C), make_shape(M, N));
    
    // 计算当前 block 负责的 tile
    int block_m = blockIdx.x * 64;
    int block_n = blockIdx.y * 64;
    
    // 提取 block 的 tile
    auto tA = local_tile(gA, make_shape(Int<64>{}, Int<K>{}), make_coord(block_m, 0));
    auto tB = local_tile(gB, make_shape(Int<K>{}, Int<64>{}), make_coord(0, block_n));
    auto tC = local_tile(gC, make_shape(Int<64>{}, Int<64>{}), make_coord(block_m, block_n));
    
    // 分配给线程
    auto thread_layout = make_layout(Int<256>{});  // 256 个线程
    auto thr_A = local_partition(tA, thread_layout, threadIdx.x);
    auto thr_B = local_partition(tB, thread_layout, threadIdx.x);
    auto thr_C = local_partition(tC, thread_layout, threadIdx.x);
    
    // 执行计算...
}
```

### 场景 2：数据拷贝（Global Memory → Shared Memory → Register）

这个示例展示了如何使用 `make_gmem_ptr`、`make_smem_ptr` 和 `make_tensor_like` 进行多级内存拷贝。

```cpp
__global__ void copy_kernel(float* src) {
    // 全局内存 Tensor（使用 make_gmem_ptr 标记）
    auto gSrc = make_tensor(make_gmem_ptr(src), make_shape(Int<128>{}, Int<128>{}));
    
    // 共享内存 Tensor（使用 make_smem_ptr 标记）
    __shared__ float smem[128 * 128];
    auto sSrc = make_tensor(make_smem_ptr(smem), make_shape(Int<128>{}, Int<128>{}));
    
    // 分配给线程（256 个线程）
    auto thread_layout = make_layout(Int<256>{});
    auto thr_gSrc = local_partition(gSrc, thread_layout, threadIdx.x);
    auto thr_sSrc = local_partition(sSrc, thread_layout, threadIdx.x);
    
    // 第一步：Global → Shared（每个线程拷贝自己负责的部分）
    copy(thr_gSrc, thr_sSrc);
    __syncthreads();
    
    // 第二步：Shared → Register（使用 make_tensor_like 创建寄存器缓冲区）
    auto rmem = make_tensor_like(thr_sSrc);  // 自动匹配形状
    copy(thr_sSrc, rmem);
    
    // 现在数据在寄存器中，可以高效处理
    // do_something(rmem);
}
```

**这个示例展示了**：
- `make_gmem_ptr` / `make_smem_ptr`：标记不同内存类型，CuTe 自动选择最优拷贝指令
- `make_tensor_like`：创建形状匹配的寄存器 Tensor，无需手动指定大小
- `local_partition`：将数据均匀分配给各个线程

### 场景 3：逐行处理矩阵（make_tensor_like 实战）

这个示例来自 [NVIDIA 官方文档](https://docs.nvidia.com/cutlass/media/docs/cpp/cute/03_tensor.html)，展示了如何用 `make_tensor_like` 优雅地处理矩阵的每一行。

```cpp
// 从全局内存逐行拷贝到寄存器并处理
Tensor gmem = make_tensor(make_gmem_ptr(ptr), make_shape(Int<8>{}, 16));  // (_8,16)
Tensor rmem = make_tensor_like(gmem(_, 0));                                // (_8)

for (int j = 0; j < size<1>(gmem); ++j) {
    copy(gmem(_, j), rmem);    // 拷贝第 j 列到寄存器
    do_something(rmem);         // 在寄存器中处理数据
}
```

**代码说明**：
- `gmem(_, 0)` 提取第一列，形状为 `(_8)`
- `make_tensor_like(gmem(_, 0))` 创建形状相同的寄存器 Tensor
- 循环中每次拷贝一列，在寄存器中高效处理
- 无需关心具体的布局，代码对任何 Layout 都有效

**扩展：处理任意大小的 Tile**

```cpp
Tensor gmem = make_tensor(make_gmem_ptr(ptr), make_shape(24, 16));  // (24,16)

auto tiler = Shape<_8,_4>{};                        // 8×4 的 tile
Tensor gmem_tiled = zipped_divide(gmem, tiler);     // ((_8,_4), Rest)
Tensor rmem = make_tensor_like(gmem_tiled(_, 0));   // ((_8,_4))

for (int j = 0; j < size<1>(gmem_tiled); ++j) {
    copy(gmem_tiled(_, j), rmem);
    do_something(rmem);
}
```

这个模式非常通用，适用于各种矩阵处理场景。

### 场景 4：Vectorized Load（向量化加载）

```cpp
// 使用 vectorized load 提高内存带宽
auto tensor = make_tensor(make_gmem_ptr<float4>(ptr), make_shape(Int<32>{}));
// 每次加载 4 个 float（float4）

// 分配给 32 个线程
auto thr_tensor = local_partition(tensor, make_layout(Int<32>{}), threadIdx.x);
// 每个线程处理 1 个 float4（即 4 个 float）

// 加载到寄存器
float4 reg_data = thr_tensor(0);
```

### 场景 5：Swizzle（交错访问模式）

```cpp
// 创建带 swizzle 的布局（避免 bank conflict）
auto swizzle_layout = composition(
    Swizzle<3, 0, 3>{},
    make_layout(make_shape(Int<64>{}, Int<64>{}))
);

// 使用 swizzle 布局创建 shared memory tensor
__shared__ float smem[64 * 64];
auto sTensor = make_tensor(make_smem_ptr(smem), swizzle_layout);

// 现在访问 sTensor 会自动应用 swizzle 模式
// 减少 shared memory bank conflict
```

---

## 高级话题

### Tensor 的多态性

```cpp
// Tensor 可以是：
// 1. 全局内存 Tensor
auto g_tensor = make_tensor(make_gmem_ptr(ptr), shape);

// 2. 共享内存 Tensor
__shared__ float smem[128];
auto s_tensor = make_tensor(make_smem_ptr(smem), shape);

// 3. 寄存器 Tensor
float reg[8];
auto r_tensor = make_tensor(reg, Int<8>{});

// 它们的接口完全相同！
```

### Const Tensor

```cpp
// 只读 Tensor
const float* data = ...;
auto tensor = make_tensor(data, make_shape(Int<128>{}));

// 编译错误：无法修改 const tensor
// tensor(0) = 5.0f;  // 编译错误

// 只能读取
float value = tensor(0);  // OK
```

### Tensor View

```cpp
// 原始 Tensor
auto tensor = make_tensor(ptr, make_shape(Int<64>{}, Int<64>{}));

// 创建视图（不拷贝数据）
auto view1 = tensor(_, make_coord(0, 32));  // 前32列
auto view2 = tensor(make_coord(16, 48), _);  // 中间32行

// 修改 view 会影响原 tensor
view1(0, 0) = 5.0f;
// tensor(0, 0) 也变成了 5.0f
```

### Tensor 的转置

```cpp
// 原始 Tensor: M×N
auto tensor = make_tensor(ptr, make_shape(Int<M>{}, Int<N>{}));

// 方式 1：交换 shape（逻辑转置，不改变内存）
auto transposed = make_tensor(ptr, 
    make_shape(Int<N>{}, Int<M>{}),
    make_stride(stride<1>(tensor), stride<0>(tensor)));

// 方式 2：使用 composition
auto col_major = make_layout(make_shape(Int<M>{}, Int<N>{}), LayoutLeft{});
auto row_major = make_layout(make_shape(Int<M>{}, Int<N>{}), LayoutRight{});
auto transposed_layout = composition(row_major, col_major);
auto transposed = make_tensor(ptr, transposed_layout);
```

---

## 调试与可视化

### 打印 Tensor 信息

```cpp
auto tensor = make_tensor(ptr, make_shape(Int<4>{}, Int<6>{}));

// 打印形状
print("Shape: "); print(shape(tensor)); print("\n");
// 输出: Shape: (_4,_6)

// 打印步长
print("Stride: "); print(stride(tensor)); print("\n");
// 输出: Stride: (_1,_4)

// 打印布局
print("Layout: "); print(layout(tensor)); print("\n");
// 输出: Layout: (_4,_6):(_1,_4)

// 打印指针地址
print("Data: "); print(tensor.data()); print("\n");
```

### 打印 Tensor 内容

```cpp
// 打印所有元素
for (int i = 0; i < size(tensor); ++i) {
    print(tensor(i)); print(" ");
}
print("\n");

// 打印 2D Tensor（行列格式）
for (int i = 0; i < size<0>(tensor); ++i) {
    for (int j = 0; j < size<1>(tensor); ++j) {
        print(tensor(i, j)); print(" ");
    }
    print("\n");
}
```

### 使用 print_tensor

```cpp
// CuTe 提供的便捷打印函数
print_tensor(tensor);

// 输出类似：
// tensor: (_4,_6):(_1,_4)
//   0.0   4.0   8.0  12.0  16.0  20.0
//   1.0   5.0   9.0  13.0  17.0  21.0
//   2.0   6.0  10.0  14.0  18.0  22.0
//   3.0   7.0  11.0  15.0  19.0  23.0
```

---

## 常见错误与解决方案

### 错误 1：Shape 不匹配

```cpp
// 错误
auto src = make_tensor(src_ptr, make_shape(Int<128>{}));
auto dst = make_tensor(dst_ptr, make_shape(Int<64>{}));
copy(src, dst);  // Size 不匹配！
```

**解决方案**：确保 shape 兼容。

```cpp
// 正确
auto dst = make_tensor(dst_ptr, make_shape(Int<128>{}));
copy(src, dst);  // OK
```

### 错误 2：越界访问

```cpp
auto tensor = make_tensor(ptr, make_shape(Int<4>{}, Int<6>{}));
tensor(5, 3) = 1.0f;  // 第一维越界（只有 0-3）
```

**解决方案**：检查索引范围。

```cpp
// 使用断言
assert(i < size<0>(tensor) && j < size<1>(tensor));
tensor(i, j) = 1.0f;
```

### 错误 3：混淆 Tensor 和 Layout

```cpp
// 错误
auto layout = make_layout(make_shape(Int<4>{}, Int<6>{}));
layout(2, 3) = 5.0f;  // Layout 没有 data，不能赋值！
```

**解决方案**：需要 Tensor 才能访问数据。

```cpp
// 正确
auto tensor = make_tensor(ptr, layout);
tensor(2, 3) = 5.0f;  // OK
```

### 错误 4：忘记同步

```cpp
// 从 global 拷贝到 shared
copy(gTensor, sTensor);
// 立即使用 sTensor（可能数据还没到！）
float val = sTensor(0);
```

**解决方案**：加同步。

```cpp
copy(gTensor, sTensor);
__syncthreads();  // 等待所有线程完成拷贝
float val = sTensor(0);  // OK
```

### 错误 5：未标记内存类型

```cpp
// 未标记，CuTe 无法选择最优指令
auto gTensor = make_tensor(ptr, make_shape(Int<128>{}));
__shared__ float smem[128];
auto sTensor = make_tensor(smem, make_shape(Int<128>{}));
copy(gTensor, sTensor);  // 可能无法使用 cp.async 等优化指令
```

**解决方案**：标记内存类型。

```cpp
// 标记后，CuTe 可以自动使用最优的拷贝指令
auto gTensor = make_tensor(make_gmem_ptr(ptr), make_shape(Int<128>{}));
auto sTensor = make_tensor(make_smem_ptr(smem), make_shape(Int<128>{}));
copy(gTensor, sTensor);  // 自动使用 cp.async（如果支持）
```

---

## 性能优化技巧

| 优化项 | 慢 | 快 | 提升 |
|--------|------|------|------|
| Shape 类型 | `int` | `Int<N>` | 编译期优化 |
| 内存访问 | 跨步访问 | 连续访问 | 内存合并 |
| 数据类型 | `float` | `float4` (vectorized) | 带宽优化 |
| 访问模式 | Bank conflict | Swizzle | 减少冲突 |
| 线程分配 | 动态计算 | Partition 预计算 | 减少运行时开销 |
| 内存标记 | 未标记指针 | `make_gmem_ptr/make_smem_ptr` | 自动选择最优指令 |
| Tensor 创建 | 手动指定形状 | `make_tensor_like` | 避免尺寸错误 |

### 优化示例 1：向量化访问

```cpp
// 慢：标量访问
auto tensor = make_tensor(make_gmem_ptr<float>(ptr), make_shape(Int<128>{}));
for (int i = 0; i < 128; ++i) {
    reg[i] = tensor(i);
}

// 快：向量化访问
auto tensor = make_tensor(make_gmem_ptr<float4>(ptr), make_shape(Int<32>{}));
for (int i = 0; i < 32; ++i) {
    reg4[i] = tensor(i);  // 一次加载 4 个 float
}
```

### 优化示例 2：使用 make_tensor_like 和内存标记

```cpp
// 慢：未标记内存，手动指定形状，容易出错
auto gmem = make_tensor(ptr, make_shape(Int<8>{}, 16));
float rmem[8];  // 手动分配，可能尺寸不匹配
for (int j = 0; j < 16; ++j) {
    for (int i = 0; i < 8; ++i) {
        rmem[i] = gmem(i, j);  // 逐元素拷贝，效率低
    }
}

// 快：标记内存，使用 make_tensor_like，自动优化
auto gmem = make_tensor(make_gmem_ptr(ptr), make_shape(Int<8>{}, 16));
auto rmem = make_tensor_like(gmem(_, 0));  // 自动匹配形状
for (int j = 0; j < size<1>(gmem); ++j) {
    copy(gmem(_, j), rmem);  // CuTe 自动优化拷贝
}
```

**性能提升**：
- 内存标记使 CuTe 能选择最优的加载指令（如向量化加载）
- `make_tensor_like` 确保形状匹配，编译器可以更好地优化
- `copy` 可以自动向量化，比手动循环快

---

## 实践任务

### 任务 1：创建和访问 Tensor

创建一个 8×12 的 Tensor，用行号×10 + 列号 填充，然后打印。

**要求**：
- 使用静态 Shape
- 使用列主序布局
- 验证 `tensor(2, 5)` 的值是否为 25

---

### 任务 2：Tensor 切片

创建一个 16×16 的 Tensor，提取：
1. 第 8 行（1D Tensor）
2. 第 5 列（1D Tensor）
3. 左上角 4×4 的子块

**要求**：
- 使用 slice 操作
- 使用 local_tile 操作
- 验证切片后的 shape

---

### 任务 3：Tensor 分区

模拟 32 个线程处理 128 个元素：
1. 创建 128 个元素的 Tensor
2. 使用 `local_partition` 分配给 32 个线程
3. 每个线程打印自己负责的元素索引

**要求**：
- 在 CUDA kernel 中实现
- 使用静态 Shape
- 验证每个线程得到 4 个元素

---

### 任务 4：使用 make_tensor_like 和内存标记

实现一个 CUDA kernel，从全局内存逐行读取矩阵到寄存器并处理：
1. 创建 8×16 的全局内存 Tensor（使用 `make_gmem_ptr`）
2. 使用 `make_tensor_like` 创建寄存器缓冲区（形状与一行相同）
3. 逐行拷贝并处理数据

**要求**：
- 使用 `make_gmem_ptr` 标记全局内存
- 使用 `make_tensor_like` 创建寄存器缓冲区
- 验证缓冲区的形状为 `(_8)`
- 完成所有 16 行的处理
  
  ---

## 总结

根据[官方文档](https://docs.nvidia.com/cutlass/media/docs/cpp/cute/03_tensor.html)，关于 CuTe Tensor 的核心要点：

### 核心概念
- **Tensor = Engine + Layout**
  - **Engine**：封装迭代器，可以被偏移和解引用
  - **Layout**：定义逻辑域，将坐标映射到偏移量

### Tensor 类型
- **Owning Tensor**：拥有数据，类似 `std::array`
  - 拷贝时深拷贝元素
  - 销毁时释放内存
  - 必须使用静态 shape 和 stride
  - 通过 `make_tensor<T>(layout)` 或 `make_tensor_like(tensor)` 创建
  
- **Nonowning Tensor**：不拥有数据，类似指针
  - 拷贝时只拷贝指针
  - 销毁时不释放内存
  - 可以使用静态或动态 shape
  - 通过 `make_tensor(ptr, layout)` 创建（默认）

### 关键操作
- **Tiling**：使用与 Layout 相同的方法平铺 Tensor
- **Slicing**：切片获取子 Tensor
- **Partitioning**：分区 = 平铺 和/或 组合 + 切片
  - **Inner Partition**：保留 tile 形状
  - **Outer Partition**：保留 remainder 形状
  - **Thread-Value Partition**：通过 composition 实现复杂映射

### 最佳实践
- 使用静态 Shape（`Int<N>`）获得最佳性能
- 用 `make_gmem_ptr` / `make_smem_ptr` 标记内存类型
- 用 `make_tensor_like` 自动创建兼容的缓冲区
- 通过引用传递 Tensor 参数
- 使用 `CUTE_STATIC_ASSERT_V` 进行编译期验证

---

## 实践

参考代码示例：[code/05_cute_tensor/cute_tensor.cu](../code/05_cute_tensor/cute_tensor.cu)
